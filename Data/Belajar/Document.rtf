{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fmodern JetBrains Mono;}{\f1\fnil\fcharset0 Calibri;}}
{\colortbl ;\red204\green120\blue50;\red169\green183\blue198;\red106\green135\blue89;\red128\green128\blue128;\red136\green136\blue198;\red104\green151\blue187;\red170\green73\blue38;}
{\*\generator Riched20 10.0.22621}\viewkind4\uc1 
\pard\box\brdrdash\brdrw0 \sa200\sl276\slmult1\cf1\f0\fs20\lang9 import \cf2 os\line\cf1 import \cf2 zipfile\line\line\cf1 from \cf2 tensorflow.python.estimator \cf1 import \cf2 keras\line\line local_zip = \cf3 './data/cats_and_dogs_filtered.zip'\line\line\cf2 zip_ref = zipfile.ZipFile(local_zip\cf1 , \cf3 'r'\cf2 )\line\line zip_ref.extractall(\cf3 './data'\cf2 )\line zip_ref.close()\line\line base_dir = \cf3 './data/cats_and_dogs_filtered'\line\line\cf2 train_dir = os.path.join(base_dir\cf1 , \cf3 'train'\cf2 )\line validation_dir = os.path.join(base_dir\cf1 , \cf3 'validation'\cf2 )\line\line\cf4 # Directory with our training cat/dog pictures\line\cf2 train_cats_dir = os.path.join(train_dir\cf1 , \cf3 'cats'\cf2 )\line train_dogs_dir = os.path.join(train_dir\cf1 , \cf3 'dogs'\cf2 )\line\line\cf4 # Directory with our validation cat/dog pictures\line\cf2 validation_cats_dir = os.path.join(validation_dir\cf1 , \cf3 'cats'\cf2 )\line validation_dogs_dir = os.path.join(validation_dir\cf1 , \cf3 'dogs'\cf2 )\line\line train_cat_fnames = os.listdir( train_cats_dir )\line train_dog_fnames = os.listdir( train_dogs_dir )\line\line\cf5 print\cf2 (train_cat_fnames[:\cf6 10\cf2 ])\line\cf5 print\cf2 (train_dog_fnames[:\cf6 10\cf2 ])\line\line\cf5 print\cf2 (\cf3 'total training cat images :'\cf1 , \cf5 len\cf2 (os.listdir(      train_cats_dir ) ))\line\cf5 print\cf2 (\cf3 'total training dog images :'\cf1 , \cf5 len\cf2 (os.listdir(      train_dogs_dir ) ))\line\line\cf5 print\cf2 (\cf3 'total validation cat images :'\cf1 , \cf5 len\cf2 (os.listdir( validation_cats_dir ) ))\line\line\cf1 import \cf2 matplotlib.image \cf1 as \cf2 mpimg\line\cf1 import \cf2 matplotlib.pyplot \cf1 as \cf2 plt\line\line\cf4 # Parameters for our graph; we'll output images in a 4x4 configuration\line\cf2 nrows = \cf6 4\line\cf2 ncols = \cf6 4\line\line\cf2 pic_index = \cf6 0 \cf4 # Index for iterating over images\line\line # Set up matplotlib fig, and size it to fit 4x4 pics\line\cf2 fig = plt.gcf()\line fig.set_size_inches(ncols * \cf6 4\cf1 , \cf2 nrows * \cf6 4\cf2 )\line\line pic_index += \cf6 8\line\line\cf2 next_cat_pix = [os.path.join(train_cats_dir\cf1 , \cf2 fname)\line                 \cf1 for \cf2 fname \cf1 in \cf2 train_cat_fnames[pic_index - \cf6 8\cf2 :pic_index]\line                 ]\line\line next_dog_pix = [os.path.join(train_dogs_dir\cf1 , \cf2 fname)\line                 \cf1 for \cf2 fname \cf1 in \cf2 train_dog_fnames[pic_index - \cf6 8\cf2 :pic_index]\line                 ]\line\line\cf1 for \cf2 i\cf1 , \cf2 img_path \cf1 in \cf5 enumerate\cf2 (next_cat_pix + next_dog_pix):\line     \cf4 # Set up subplot; subplot indices start at 1\line     \cf2 sp = plt.subplot(nrows\cf1 , \cf2 ncols\cf1 , \cf2 i + \cf6 1\cf2 )\line     sp.axis(\cf3 'Off'\cf2 )  \cf4 # Don't show axes (or gridlines)\line\line     \cf2 img = mpimg.imread(img_path)\line     plt.imshow(img)\line\line plt.show()\line\line\cf1 import \cf2 tensorflow \cf1 as \cf2 tf\line model = tf.keras.models.Sequential([\line     \cf4 # Note the input shape is the desired size of the image 150x150 with 3 bytes color\line     \cf2 tf.keras.layers.Conv2D(\cf6 16\cf1 , \cf2 (\cf6 3\cf1 ,\cf6 3\cf2 )\cf1 , \cf7 activation\cf2 =\cf3 'relu'\cf1 , \cf7 input_shape\cf2 =(\cf6 150\cf1 , \cf6 150\cf1 , \cf6 3\cf2 ))\cf1 ,\line     \cf2 tf.keras.layers.MaxPooling2D(\cf6 2\cf1 ,\cf6 2\cf2 )\cf1 ,\line     \cf2 tf.keras.layers.Conv2D(\cf6 32\cf1 , \cf2 (\cf6 3\cf1 ,\cf6 3\cf2 )\cf1 , \cf7 activation\cf2 =\cf3 'relu'\cf2 )\cf1 ,\line     \cf2 tf.keras.layers.MaxPooling2D(\cf6 2\cf1 ,\cf6 2\cf2 )\cf1 ,\line     \cf2 tf.keras.layers.Conv2D(\cf6 64\cf1 , \cf2 (\cf6 3\cf1 ,\cf6 3\cf2 )\cf1 , \cf7 activation\cf2 =\cf3 'relu'\cf2 )\cf1 ,\line     \cf2 tf.keras.layers.MaxPooling2D(\cf6 2\cf1 ,\cf6 2\cf2 )\cf1 ,\line     \cf4 # Flatten the results to feed into a DNN\line     \cf2 tf.keras.layers.Flatten()\cf1 ,\line     \cf4 # 512 neuron hidden layer\line     \cf2 tf.keras.layers.Dense(\cf6 512\cf1 , \cf7 activation\cf2 =\cf3 'relu'\cf2 )\cf1 ,\line     \cf4 # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\line     \cf2 tf.keras.layers.Dense(\cf6 1\cf1 , \cf7 activation\cf2 =\cf3 'sigmoid'\cf2 )\line ])\line\line model.summary()\line\line\cf1 from \cf2 tensorflow.keras.optimizers \cf1 import \cf2 RMSprop\line\line model.compile(\cf7 optimizer\cf2 =RMSprop(\cf7 learning_rate\cf2 =\cf6 0.001\cf2 )\cf1 ,\line               \cf7 loss\cf2 =\cf3 'binary_crossentropy'\cf1 ,\line               \cf7 metrics \cf2 = [\cf3 'accuracy'\cf2 ])\line\line\cf1 from \cf2 tensorflow.keras.preprocessing.image \cf1 import \cf2 ImageDataGenerator\line\line\cf4 # All images will be rescaled by 1./255.\line\cf2 train_datagen = ImageDataGenerator( \cf7 rescale \cf2 = \cf6 1.0\cf2 /\cf6 255. \cf2 )\line test_datagen  = ImageDataGenerator( \cf7 rescale \cf2 = \cf6 1.0\cf2 /\cf6 255. \cf2 )\line\line\cf4 # --------------------\line # Flow training images in batches of 20 using train_datagen generator\line # --------------------\line\cf2 train_generator = train_datagen.flow_from_directory(train_dir\cf1 ,\line                                                     \cf7 batch_size\cf2 =\cf6 20\cf1 ,\line                                                     \cf7 class_mode\cf2 =\cf3 'binary'\cf1 ,\line                                                     \cf7 target_size\cf2 =(\cf6 150\cf1 , \cf6 150\cf2 ))\line\cf4 # --------------------\line # Flow validation images in batches of 20 using test_datagen generator\line # --------------------\line\cf2 validation_generator =  test_datagen.flow_from_directory(validation_dir\cf1 ,\line                                                          \cf7 batch_size\cf2 =\cf6 20\cf1 ,\line                                                          \cf7 class_mode\cf2 =\cf3 'binary'\cf1 ,\line                                                          \cf7 target_size\cf2 =(\cf6 150\cf1 , \cf6 150\cf2 ))\line\line history = model.fit(train_generator\cf1 ,\line                               \cf7 validation_data\cf2 =validation_generator\cf1 ,\line                               \cf7 steps_per_epoch\cf2 =\cf6 100\cf1 ,\line                               \cf7 epochs\cf2 =\cf6 15\cf1 ,\line                               \cf7 validation_steps\cf2 =\cf6 50\cf1 ,\line                               \cf7 verbose\cf2 =\cf6 2\cf2 )\line\line\cf4 #-----------------------------------------------------------\line # Retrieve a list of list results on training and test data\line # sets for each training epoch\line #-----------------------------------------------------------\line\cf2 acc      = history.history[     \cf3 'accuracy' \cf2 ]\line val_acc  = history.history[ \cf3 'val_accuracy' \cf2 ]\line loss     = history.history[    \cf3 'loss' \cf2 ]\line val_loss = history.history[\cf3 'val_loss' \cf2 ]\line\line epochs   = \cf5 range\cf2 (\cf5 len\cf2 (acc)) \cf4 # Get number of epochs\line\line #------------------------------------------------\line # Plot training and validation accuracy per epoch\line #------------------------------------------------\line\cf2 plt.plot( epochs\cf1 , \cf2 acc\cf1 , \cf7 label\cf2 =\cf3 'Training'\cf2 )\line plt.plot( epochs\cf1 , \cf2 val_acc\cf1 , \cf7 label\cf2 =\cf3 'Validation'\cf2 )\line plt.title (\cf3 'Training and validation accuracy'\cf2 )\line plt.legend()\line plt.figure()\line\line\cf4 #------------------------------------------------\line # Plot training and validation loss per epoch\line #------------------------------------------------\line\cf2 plt.plot(epochs\cf1 ,     \cf2 loss\cf1 , \cf7 label\cf2 =\cf3 'Training'\cf2 )\line plt.plot(epochs\cf1 , \cf2 val_loss\cf1 , \cf7 label\cf2 =\cf3 'Validation'\cf2 )\line plt.legend()\line plt.title(\cf3 'Training and validation loss'\cf2 )\line\line\cf4 # EXERCISE: Save the trained model as a Keras HDF5 file.\line\line\cf2 saved_model_path = \cf3 "./my_model.h5"\line\line\cf4 # YOUR CODE HERE\line\cf2 model.save(saved_model_path)\line\cf5 print\cf2 (saved_model_path)\line\line\line\par

\pard\sa200\sl276\slmult1\cf0\f1\fs22\par
}
 